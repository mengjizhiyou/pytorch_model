{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "custom_data.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "8DdWB0ezOQ0d",
        "outputId": "3df75be1-e3c8-47ac-a26e-e188e48293e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.10.0+cu111'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "import torch\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric\n",
        "!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "!pip install torch-spline-conv -f https://data.pyg.org/whl/torch-1.10.0+cu111.html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXSH71IoOvtH",
        "outputId": "7fc90cfa-a097-4821-a434-4b278c54ad9f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.7/dist-packages (2.0.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.21.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.3.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (3.0.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (4.63.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (2.11.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch_geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch_geometric) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch_geometric) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torch_geometric) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torch_geometric) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch_geometric) (2.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch_geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch_geometric) (1.1.0)\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.7/dist-packages (2.0.9)\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.7/dist-packages (0.6.13)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-sparse) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy->torch-sparse) (1.21.5)\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.7/dist-packages (1.6.0)\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
            "Requirement already satisfied: torch-spline-conv in /usr/local/lib/python3.7/dist-packages (1.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.datasets import TUDataset\n",
        "dataset = TUDataset('./', name=\"PROTEINS_full\", use_node_attr=True)"
      ],
      "metadata": {
        "id": "Xf8S1Ut-OzeS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMff_TscO1mw",
        "outputId": "3dc48266-a736-45b0-cbc7-44b5635df0b0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(edge_index=[2, 162], x=[42, 32], y=[1])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.len()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWPEx-1LO4LU",
        "outputId": "43ff09f7-5f0a-409b-9aac-c5a44bea62ca"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1113"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Dataset, Data\n",
        "import os\n",
        "from typing import List\n",
        "from torch_geometric.io import read_txt_array\n",
        "import torch.nn.functional as F\n",
        "from torch_sparse import coalesce\n",
        "from torch_geometric.utils import remove_self_loops\n",
        "from torch_geometric.data.separate import separate\n",
        "import copy\n",
        "from typing import Callable, Dict, Iterable, List, Optional, Tuple, Union\n",
        "from collections.abc import Mapping\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "gg1v_rz4OTQ4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDatset(Dataset): \n",
        "\n",
        "  def __init__(self, root='./PROTEINS_full', filepath='./PROTEINS_full/raw', name='custom', \n",
        "               use_edge_attr=True, transform=None, \n",
        "               pre_transform=None, pre_filter=None):\n",
        "    \"\"\"\n",
        "    root: 数据集保存的地方。\n",
        "    会产生两个文件夹：\n",
        "      raw_dir(downloaded dataset) 和 processed_dir(processed data)。\n",
        "    \"\"\"      \n",
        "    \n",
        "    self.name = name\n",
        "    self.root = root\n",
        "    self.filepath = filepath      \n",
        "    self.filenames = os.listdir(filepath)\n",
        "    self.use_edge_attr = use_edge_attr\n",
        "    self.pre_transform = pre_transform\n",
        "    self.pre_filter = pre_filter\n",
        "\n",
        "    super().__init__(root, transform, pre_transform, pre_filter)\n",
        "\n",
        "    self.data, self.slices = torch.load(self.processed_paths[0])\n",
        "    # self.slices：一个切片字典，用于从该对象重构单个示例\n",
        "\n",
        "  @property\n",
        "  def raw_dir(self):\n",
        "    \"\"\"原始文件的文件夹\"\"\"\n",
        "    return self.filepath\n",
        "  \n",
        "  @property\n",
        "  def processed_dir(self):\n",
        "    \"\"\"处理后文件的文件夹\"\"\"\n",
        "    return os.path.join(self.root, self.name)\n",
        "  \n",
        "  @property\n",
        "  def raw_file_names(self) -> List[str]:\n",
        "    \"\"\"\"原始文件的文件名，如果存在则不会触发download\"\"\"\n",
        "    return self.filenames\n",
        "  \n",
        "  @property\n",
        "  def processed_file_names(self) -> str:\n",
        "    \"\"\"处理后的文件名，如果在 processed_dir 中找到则跳过 process\"\"\"\n",
        "    return ['data.pt']\n",
        "  \n",
        "  def download(self):\n",
        "    \"\"\"这里不需要下载\"\"\"\n",
        "    pass\n",
        "\n",
        "  #-----------------------------------------------------\n",
        "  # 添加一些特征处理，如果不用处理，这部分可以不要\n",
        "  #----------------------------------------------------- \n",
        "  def _get_node_features(self):\n",
        "    \"\"\"获取结点特征\"\"\"\n",
        "    print(self.filepath)\n",
        "    path = os.path.join(self.filepath, 'PROTEINS_full_node_attributes.txt')\n",
        "    node_attributes = read_txt_array(path, sep=',')\n",
        "    return node_attributes\n",
        "  \n",
        "  def _get_node_labels(self):\n",
        "    \"\"\"获取结点标签\"\"\"\n",
        "    path = os.path.join(self.filepath, 'PROTEINS_full_node_labels.txt')\n",
        "    node_labels = read_txt_array(path, sep=',', dtype=torch.long)\n",
        "    if node_labels.dim() == 1:\n",
        "      node_labels = node_labels.unsqueeze(-1)\n",
        "    node_labels = node_labels - node_labels.min(dim=0)[0]\n",
        "    node_labels = node_labels.unbind(dim=-1)\n",
        "    node_labels = [F.one_hot(x, num_classes=-1) for x in node_labels]\n",
        "    node_labels = torch.cat(node_labels, dim=-1).to(torch.float)\n",
        "    return node_labels   \n",
        "\n",
        "  def _get_adjacent(self):\n",
        "    \"\"\"获取边索引\"\"\"\n",
        "    path = os.path.join(self.filepath, 'PROTEINS_full_A.txt')\n",
        "    edge_index = read_txt_array(path, sep=',', dtype=torch.long).t() - 1\n",
        "    return edge_index\n",
        "\n",
        "  def _get_batch(self):\n",
        "    \"\"\"获取 batch 索引\"\"\"\n",
        "    path = os.path.join(self.filepath, 'PROTEINS_full_graph_indicator.txt')\n",
        "    batch = read_txt_array(path, sep=',', dtype=torch.long) - 1\n",
        "    return batch\n",
        "\n",
        "  def _get_graph_labels(self):\n",
        "    \"\"\"获取图标签\"\"\"\n",
        "    path = os.path.join(self.filepath, 'PROTEINS_full_graph_labels.txt')\n",
        "    y = read_txt_array(path, sep=',', dtype=torch.long)\n",
        "    _, y = y.unique(sorted=True, return_inverse=True)\n",
        "    return y\n",
        "\n",
        "  #-----------------------------------------------------\n",
        "  # 数据处理主程序\n",
        "  #----------------------------------------------------- \n",
        "\n",
        "  def process(self):\n",
        "    \"\"\"主程序，对原始数据进行处理\"\"\"\n",
        "\n",
        "    edge_index = self._get_adjacent()\n",
        "    batch = self._get_batch()\n",
        "    node_features = self._get_node_features()\n",
        "    node_labels = self._get_node_labels()\n",
        "    x = cat([node_features, node_labels])\n",
        "    y = self._get_graph_labels()\n",
        "    num_nodes = edge_index.max().item() + 1 if x is None else x.size(0)\n",
        "    edge_attr = None\n",
        "    edge_index, edge_attr = remove_self_loops(edge_index, edge_attr)\n",
        "    edge_index, edge_attr = coalesce(edge_index, edge_attr, num_nodes, num_nodes)\n",
        "    data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
        "    self.data, self.slices = split(data, batch)\n",
        "\n",
        "    if self.pre_filter is not None:\n",
        "        data_list = [self.get(idx) for idx in range(len(self))]\n",
        "        data_list = [data for data in data_list if self.pre_filter(data)]\n",
        "        self.data = data_list\n",
        "\n",
        "    if self.pre_transform is not None:\n",
        "        data_list = [self.get(idx) for idx in range(len(self))]\n",
        "        data_list = [self.pre_transform(data) for data in data_list]\n",
        "        self.data = data_list\n",
        "    \n",
        "    torch.save((self.data, self.slices), self.processed_paths[0])\n",
        "  \n",
        "  \n",
        "  #-----------------------------------------------------\n",
        "  # 获取单个图，第idx图\n",
        "  #----------------------------------------------------- \n",
        "  def get(self, idx):\n",
        "    \"\"\"根据索引获取数据\"\"\"\n",
        "    if self.len() == 1:\n",
        "      return copy.copy(self.data)\n",
        "\n",
        "    if not hasattr(self, '_data_list') or self._data_list is None:\n",
        "      self._data_list = self.len() * [None]\n",
        "    elif self._data_list[idx] is not None:\n",
        "      return copy.copy(self._data_list[idx])\n",
        "\n",
        "    \"\"\"\n",
        "    separate:\n",
        "    将单个元素与索引“idx”处的“批处理”分隔开。\n",
        "    “separate”可以通过单独分离所有的存储来处理同构和异质数据对象。\n",
        "    此外，“separate”可以处理嵌套的数据结构，如字典和列表。\n",
        "    \"\"\"\n",
        "    data = separate(cls=self.data.__class__,batch=self.data,idx=idx,slice_dict=self.slices,decrement=False,)\n",
        "\n",
        "    self._data_list[idx] = copy.copy(data)  \n",
        "    return data\n",
        "  \n",
        "  def len(self) -> int:\n",
        "      if self.slices is None:\n",
        "          return 1\n",
        "      for _, value in nested_iter(self.slices):\n",
        "          return len(value) - 1\n",
        "      return 0\n",
        "\n",
        "  def __repr__(self) -> str:\n",
        "      return f'{self.name}({len(self)})'\n",
        "\n",
        "\n",
        "#-----------------------------------------------------\n",
        "# 辅助函数\n",
        "#----------------------------------------------------- \n",
        "def cat(seq):\n",
        "  seq = [item for item in seq if item is not None]\n",
        "  seq = [item.unsqueeze(-1) if item.dim() == 1 else item for item in seq]\n",
        "  return torch.cat(seq, dim=-1) if len(seq) > 0 else None   \n",
        "\n",
        "def split(data, batch):\n",
        "  node_slice = torch.cumsum(torch.from_numpy(np.bincount(batch)), 0)\n",
        "  node_slice = torch.cat([torch.tensor([0]), node_slice])\n",
        "\n",
        "  row, _ = data.edge_index\n",
        "  edge_slice = torch.cumsum(torch.from_numpy(np.bincount(batch[row])), 0)\n",
        "  edge_slice = torch.cat([torch.tensor([0]), edge_slice])\n",
        "\n",
        "  # Edge indices should start at zero for every graph.\n",
        "  data.edge_index -= node_slice[batch[row]].unsqueeze(0)\n",
        "\n",
        "  slices = {'edge_index': edge_slice}\n",
        "  if data.x is not None:\n",
        "    slices['x'] = node_slice\n",
        "  else:\n",
        "    # Imitate `collate` functionality:\n",
        "    data._num_nodes = torch.bincount(batch).tolist()\n",
        "    data.num_nodes = batch.numel()\n",
        "  if data.edge_attr is not None:\n",
        "    slices['edge_attr'] = edge_slice\n",
        "  if data.y is not None:\n",
        "    if data.y.size(0) == batch.size(0):\n",
        "      slices['y'] = node_slice\n",
        "    else:\n",
        "      slices['y'] = torch.arange(0, batch[-1] + 2, dtype=torch.long)\n",
        "  return data, slices\n",
        "\n",
        "\n",
        "def nested_iter(mapping: Mapping) -> Iterable:\n",
        "  for key, value in mapping.items():\n",
        "    if isinstance(value, Mapping):\n",
        "      for inner_key, inner_value in nested_iter(value):\n",
        "        yield inner_key, inner_value\n",
        "    else:\n",
        "        yield key, value"
      ],
      "metadata": {
        "id": "qDcXLCiIOUqB"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDatset()"
      ],
      "metadata": {
        "id": "jyO91V5BOn5Z"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RA9w4GoyOqVI",
        "outputId": "dd380b7d-d707-4493-ea8e-e70c5c9e2e4e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(edge_index=[2, 162], x=[42, 32], y=[1])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}